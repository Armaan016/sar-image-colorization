{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2008381,"sourceType":"datasetVersion","datasetId":1201791},{"sourceId":10369862,"sourceType":"datasetVersion","datasetId":6423164},{"sourceId":10370703,"sourceType":"datasetVersion","datasetId":6423759},{"sourceId":207843806,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:31:29.798609Z","iopub.execute_input":"2025-01-05T12:31:29.798948Z","iopub.status.idle":"2025-01-05T12:31:29.804283Z","shell.execute_reply.started":"2025-01-05T12:31:29.798915Z","shell.execute_reply":"2025-01-05T12:31:29.803232Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.applications import VGG19\n\n# Define U-Net Generator with Additional Skip Connections\ndef unet_generator(output_channels):\n    inputs = layers.Input(shape=[256, 256, 3])\n\n    # Downsampling layers (Encoder)\n    down_stack = [\n        layers.Conv2D(64, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2D(128, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2D(256, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2D(512, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2D(512, 4, strides=2, padding='same', activation='relu')\n    ]\n\n    # Upsampling layers (Decoder)\n    up_stack = [\n        layers.Conv2DTranspose(512, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2DTranspose(256, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2DTranspose(128, 4, strides=2, padding='same', activation='relu'),\n        layers.Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'),\n    ]\n\n    # Connecting layers with skip connections\n    x = inputs\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = layers.Concatenate()([x, skip])\n\n    # Final output layer\n    outputs = layers.Conv2DTranspose(output_channels, 4, strides=2, padding='same', activation='tanh')(x)\n    return Model(inputs=inputs, outputs=outputs)\n\ngenerator = unet_generator(3)\ngenerator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:31:53.853538Z","iopub.execute_input":"2025-01-05T12:31:53.853881Z","iopub.status.idle":"2025-01-05T12:31:54.779825Z","shell.execute_reply.started":"2025-01-05T12:31:53.853853Z","shell.execute_reply":"2025-01-05T12:31:54.778937Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m3,136\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m131,200\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m524,544\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,097,664\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m4,194,816\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m4,194,816\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,194,560\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m1,048,704\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m262,208\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │          \u001b[38;5;34m6,147\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,560</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,208</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_transpose_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,147</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,657,795\u001b[0m (63.54 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,657,795</span> (63.54 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,657,795\u001b[0m (63.54 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,657,795</span> (63.54 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Define PatchGAN Discriminator\ndef patchgan_discriminator():\n    model = tf.keras.Sequential()\n    model.add(layers.InputLayer(input_shape=[256, 256, 3]))  # Adjust input shape\n    model.add(layers.Conv2D(64, 4, strides=2, padding='same', activation='relu'))\n    model.add(layers.Conv2D(128, 4, strides=2, padding='same', activation='relu'))\n    model.add(layers.Conv2D(256, 4, strides=2, padding='same', activation='relu'))\n    model.add(layers.Conv2D(1, 4, strides=1, padding='same', activation='sigmoid'))  # Binary classification (real or fake)\n    return model\n\n# Initialize discriminator\ndiscriminator = patchgan_discriminator()\ndiscriminator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:31:57.332457Z","iopub.execute_input":"2025-01-05T12:31:57.332786Z","iopub.status.idle":"2025-01-05T12:31:57.386951Z","shell.execute_reply.started":"2025-01-05T12:31:57.332760Z","shell.execute_reply":"2025-01-05T12:31:57.386280Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m3,136\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m131,200\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m524,544\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │           \u001b[38;5;34m4,097\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m662,977\u001b[0m (2.53 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">662,977</span> (2.53 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m662,977\u001b[0m (2.53 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">662,977</span> (2.53 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Define VGG-based Perceptual Loss\nclass VGGPerceptualLoss(tf.keras.Model):\n    def __init__(self):\n        super(VGGPerceptualLoss, self).__init__()\n        vgg = VGG19(include_top=False, weights='imagenet')\n        vgg.trainable = False\n        self.model = Model(inputs=vgg.input, outputs=vgg.get_layer('block4_conv1').output)\n\n    def call(self, y_true, y_pred):\n        y_true_vgg = self.model(y_true)\n        y_pred_vgg = self.model(y_pred)\n        return tf.reduce_mean(tf.abs(y_true_vgg - y_pred_vgg))\n\n# Loss functions\ndef generator_loss(disc_generated_output, gen_output, target, perceptual_loss_model):\n    # L1 loss\n    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n\n    # Adversarial loss\n    gan_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n        logits=disc_generated_output, labels=tf.ones_like(disc_generated_output)))\n\n    # Perceptual loss\n    perceptual_loss = perceptual_loss_model(target, gen_output)\n\n    # Weighted loss combination\n    return gan_loss + 50 * l1_loss + 10 * perceptual_loss\n\ndef discriminator_loss(disc_real_output, disc_generated_output):\n    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n        logits=disc_real_output, labels=tf.ones_like(disc_real_output)))\n    generated_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n        logits=disc_generated_output, labels=tf.zeros_like(disc_generated_output)))\n    return real_loss + generated_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:32:00.475749Z","iopub.execute_input":"2025-01-05T12:32:00.476146Z","iopub.status.idle":"2025-01-05T12:32:00.485872Z","shell.execute_reply.started":"2025-01-05T12:32:00.476110Z","shell.execute_reply":"2025-01-05T12:32:00.484871Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"### load the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T10:26:50.941534Z","iopub.execute_input":"2025-01-05T10:26:50.941828Z","iopub.status.idle":"2025-01-05T10:26:50.945271Z","shell.execute_reply.started":"2025-01-05T10:26:50.941806Z","shell.execute_reply":"2025-01-05T10:26:50.944442Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Modify to load SAR and RGB images from separate directories\ndef load_images_from_directory(sar_dir, rgb_dir, image_size=(256, 256)):\n    sar_images = []\n    rgb_images = []\n\n    # List all files in the SAR and RGB directories\n    sar_files = os.listdir(sar_dir)\n    rgb_files = os.listdir(rgb_dir)\n\n    # Sort the files so they match correctly\n    sar_files.sort()\n    rgb_files.sort()\n\n    for sar_file, rgb_file in zip(sar_files, rgb_files):\n        if sar_file.endswith(\".png\") and rgb_file.endswith(\".png\"):\n            # Load and preprocess SAR image (grayscale)\n            sar_image = load_img(os.path.join(sar_dir, sar_file), target_size=image_size, color_mode='grayscale')\n            sar_image = img_to_array(sar_image)\n            sar_image = np.repeat(sar_image, 3, axis=-1)  # Convert grayscale to RGB by duplicating the channel\n            sar_image = (sar_image - 127.5) / 127.5  # Normalize to [-1, 1]\n            sar_images.append(sar_image)\n\n            # Load and preprocess RGB image (color)\n            rgb_image = load_img(os.path.join(rgb_dir, rgb_file), target_size=image_size)\n            rgb_image = img_to_array(rgb_image)\n            rgb_image = (rgb_image - 127.5) / 127.5  # Normalize to [-1, 1]\n            rgb_images.append(rgb_image)\n\n    return np.array(sar_images), np.array(rgb_images)\n\n# Replace with the correct paths to your directories\nsar_dir = \"/kaggle/input/sentinel12-image-pairs-segregated-by-terrain/v_2/agri/s1\"\nrgb_dir = \"/kaggle/input/sentinel12-image-pairs-segregated-by-terrain/v_2/agri/s2\"\n\n# Load the images\nsar_images, rgb_images = load_images_from_directory(sar_dir, rgb_dir, image_size=(256, 256))\n\n# Check the shape of loaded images\nprint(sar_images.shape, rgb_images.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:32:06.176349Z","iopub.execute_input":"2025-01-05T12:32:06.176786Z","iopub.status.idle":"2025-01-05T12:33:22.707509Z","shell.execute_reply.started":"2025-01-05T12:32:06.176743Z","shell.execute_reply":"2025-01-05T12:33:22.706581Z"}},"outputs":[{"name":"stdout","text":"(4000, 256, 256, 3) (4000, 256, 256, 3)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming sar_images and rgb_images are loaded NumPy arrays\nsar_train, sar_temp, rgb_train, rgb_temp = train_test_split(sar_images, rgb_images, test_size=0.3, random_state=42)\nsar_val, sar_test, rgb_val, rgb_test = train_test_split(sar_temp, rgb_temp, test_size=0.5, random_state=42)\n\n# Create tf.data.Datasets\ndef create_dataset(sar_images, rgb_images, batch_size=16):\n    dataset = tf.data.Dataset.from_tensor_slices((sar_images, rgb_images))\n    dataset = dataset.shuffle(buffer_size=len(sar_images))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\n\ntrain_dataset = create_dataset(sar_train, rgb_train, batch_size=8)\nval_dataset = create_dataset(sar_val, rgb_val, batch_size=8)\ntest_dataset = create_dataset(sar_test, rgb_test, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:33:22.708817Z","iopub.execute_input":"2025-01-05T12:33:22.709144Z","iopub.status.idle":"2025-01-05T12:33:40.345122Z","shell.execute_reply.started":"2025-01-05T12:33:22.709109Z","shell.execute_reply":"2025-01-05T12:33:40.344409Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"@tf.function\ndef train_step(input_image, target, perceptual_loss_model, generator_optimizer, discriminator_optimizer):\n    with tf.GradientTape(persistent=True) as tape:\n        gen_output = generator(input_image, training=True)\n        disc_real_output = discriminator(target, training=True)\n        disc_generated_output = discriminator(gen_output, training=True)\n\n        gen_loss = generator_loss(disc_generated_output, gen_output, target, perceptual_loss_model)\n        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n\n    gradients_of_generator = tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    # Apply gradients\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n    del tape  # Free memory for the tape\n\n    return gen_loss, disc_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:34:40.572549Z","iopub.execute_input":"2025-01-05T12:34:40.573166Z","iopub.status.idle":"2025-01-05T12:34:40.579209Z","shell.execute_reply.started":"2025-01-05T12:34:40.573134Z","shell.execute_reply":"2025-01-05T12:34:40.578318Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Define Adam optimizers\ngenerator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n\ndef train(train_dataset, val_dataset, epochs):\n    # Instantiate perceptual loss model\n    perceptual_loss_model = VGGPerceptualLoss()\n\n    # Define Adam optimizers\n    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n\n    for epoch in range(epochs):\n        print(f\"Starting Epoch {epoch + 1}/{epochs}\")\n        for input_image, target in train_dataset:\n            gen_loss, disc_loss = train_step(input_image, target, perceptual_loss_model, generator_optimizer, discriminator_optimizer)\n\n        print(f\"Epoch {epoch + 1}: Gen Loss: {gen_loss}, Disc Loss: {disc_loss}\")\n\n        # Evaluate on validation data\n        val_gen_loss = 0\n        val_disc_loss = 0\n        val_batches = 0\n        for val_input_image, val_target in val_dataset:\n            gen_output = generator(val_input_image, training=False)\n            disc_real_output = discriminator(val_target, training=False)\n            disc_generated_output = discriminator(gen_output, training=False)\n\n            val_gen_loss += generator_loss(disc_generated_output, gen_output, val_target, perceptual_loss_model)\n            val_disc_loss += discriminator_loss(disc_real_output, disc_generated_output)\n            val_batches += 1\n\n        val_gen_loss /= val_batches\n        val_disc_loss /= val_batches\n\n        print(f\"Validation: Gen Loss: {val_gen_loss}, Disc Loss: {val_disc_loss}\")\n\n        \ntrain(train_dataset, val_dataset, epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T12:34:42.599934Z","iopub.execute_input":"2025-01-05T12:34:42.600226Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nStarting Epoch 1/20\nEpoch 1: Gen Loss: 98.44144439697266, Disc Loss: 1.1684757471084595\nValidation: Gen Loss: 93.24346923828125, Disc Loss: 1.1858350038528442\nStarting Epoch 2/20\nEpoch 2: Gen Loss: 88.62085723876953, Disc Loss: 1.009641170501709\nValidation: Gen Loss: 88.06364440917969, Disc Loss: 1.0201491117477417\nStarting Epoch 3/20\nEpoch 3: Gen Loss: 91.28565979003906, Disc Loss: 1.00897216796875\nValidation: Gen Loss: 85.98218536376953, Disc Loss: 1.0085806846618652\nStarting Epoch 4/20\nEpoch 4: Gen Loss: 85.98098754882812, Disc Loss: 1.0071009397506714\nValidation: Gen Loss: 82.6901626586914, Disc Loss: 1.0084325075149536\nStarting Epoch 5/20\nEpoch 5: Gen Loss: 80.69319152832031, Disc Loss: 1.0073978900909424\nValidation: Gen Loss: 80.296142578125, Disc Loss: 1.0125445127487183\nStarting Epoch 6/20\nEpoch 6: Gen Loss: 82.61544799804688, Disc Loss: 1.0071766376495361\nValidation: Gen Loss: 77.51099395751953, Disc Loss: 1.0071769952774048\nStarting Epoch 7/20\nEpoch 7: Gen Loss: 75.49795532226562, Disc Loss: 1.006696343421936\nValidation: Gen Loss: 73.91761779785156, Disc Loss: 1.007340669631958\nStarting Epoch 8/20\nEpoch 8: Gen Loss: 68.78407287597656, Disc Loss: 1.0070583820343018\nValidation: Gen Loss: 71.07063293457031, Disc Loss: 1.0109038352966309\nStarting Epoch 9/20\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"generator.save(\"pix2pix_generator_final.h5\")\ndiscriminator.save(\"pix2pix_discriminator_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T07:29:48.128710Z","iopub.execute_input":"2025-01-05T07:29:48.129092Z","iopub.status.idle":"2025-01-05T07:29:48.297591Z","shell.execute_reply.started":"2025-01-05T07:29:48.129061Z","shell.execute_reply":"2025-01-05T07:29:48.296694Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport random\nfrom skimage.metrics import structural_similarity as ssim\nimport tensorflow as tf\n\n# Visualize generated images for random test samples and calculate SSIM, PSNR\ndef visualize_results(test_input, test_target, gen_output, epoch=None):\n    # Rescale back to [0, 1] for visualization\n    test_input = (test_input[0] * 0.5 + 0.5).numpy()\n    test_target = (test_target[0] * 0.5 + 0.5).numpy()\n    gen_output = (gen_output[0] * 0.5 + 0.5).numpy()\n    \n    # Calculate SSIM and PSNR\n    ssim_value = ssim(test_target, gen_output, multichannel=True)\n    psnr_value = tf.image.psnr(test_target, gen_output, max_val=1.0).numpy()\n\n    # Print SSIM and PSNR\n    print(f\"SSIM: {ssim_value:.4f}, PSNR: {psnr_value:.4f}\")\n    \n    # Plotting images\n    plt.figure(figsize=(12, 12))\n\n    # SAR image\n    plt.subplot(1, 3, 1)\n    plt.imshow(test_input)\n    plt.title(\"Input (SAR)\")\n    plt.axis(\"off\")\n\n    # True RGB image\n    plt.subplot(1, 3, 2)\n    plt.imshow(test_target)\n    plt.title(\"True RGB\")\n    plt.axis(\"off\")\n\n    # Generated RGB image\n    plt.subplot(1, 3, 3)\n    plt.imshow(gen_output)\n    plt.title(\"Generated Image\")\n    plt.axis(\"off\")\n\n    if epoch is not None:\n        plt.suptitle(f\"Epoch {epoch + 1}\")\n    plt.show()\n\n# Function to test and visualize random samples from the test dataset\ndef test_on_random_samples(test_dataset, generator, num_samples=5):\n    # Select `num_samples` random batches from the test dataset\n    random_indices = random.sample(range(len(test_dataset)), num_samples)\n    \n    for idx in random_indices:\n        test_input, test_target = list(test_dataset.skip(idx).take(1))[0]\n        \n        # Generate the image\n        gen_output = generator(test_input, training=False)\n        \n        # Visualize Results with SSIM and PSNR\n        visualize_results(test_input, test_target, gen_output)\n\n# After training completes, visualize results for 5 random test samples\ntest_on_random_samples(test_dataset, generator, num_samples=5)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-05T12:21:10.412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}